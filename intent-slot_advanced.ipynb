{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Intent and Slot Filling with Curriculum Learning\n\nThis notebook demonstrates implementing a joint intent classification and slot filling model for natural language understanding (NLU) using curriculum learning.\n\n## What is Curriculum Learning?\n\nCurriculum learning is a training strategy inspired by the way humans learn, where models are trained on examples of gradually increasing difficulty. The key ideas are:\n\n1. **Start Simple**: Begin with easier examples that have clear patterns\n2. **Progressive Difficulty**: Gradually introduce more complex examples\n3. **Competence-Based Progression**: Advance to harder examples once the model masters simpler ones\n\n## Benefits of Curriculum Learning\n\n- **Faster Convergence**: Often leads to faster training, especially in the early stages\n- **Better Generalization**: Can help models generalize better by building foundational knowledge first\n- **Avoiding Local Minima**: May help avoid poor local minima by guiding optimization\n\n## Implementation Approaches\n\nIn this notebook, we implement curriculum learning for joint intent and slot prediction in several ways:\n\n1. **Static Curriculum**: Pre-define difficulty based on features like sentence length, number of slots, etc.\n2. **Competence-Based Curriculum**: Dynamically adjust the curriculum based on model performance\n3. **Alternative Difficulty Metrics**: Explore different ways to measure example difficulty\n\nWe compare these approaches with standard training to demonstrate the benefits of curriculum learning.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW\nfrom transformers import BertTokenizerFast, BertModel\nfrom collections import defaultdict\nimport json\n\n# --------- 1. Expanded Training Data ---------\n# Your prompts split into words with slot labels and intent\n\ndata = [\n    # add_expense\n    {\"words\": [\"Add\", \"expense\", \"of\", \"$20\", \"to\", \"group\", \"Travel\", \"Friends\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"B-amount\", \"O\", \"O\", \"B-group\", \"I-group\"], \"intent\": \"add_expense\"},\n    {\"words\": [\"Add\", \"rent\", \"of\", \"$1200\", \"to\", \"House\", \"Bills\", \"group\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"B-amount\", \"O\", \"B-group\", \"I-group\", \"O\"], \"intent\": \"add_expense\"},\n    {\"words\": [\"Add\", \"$95\", \"groceries\", \"to\", \"House\", \"Bills\", \"group\"], \n     \"slots\": [\"O\", \"B-amount\", \"O\", \"O\", \"B-group\", \"I-group\", \"O\"], \"intent\": \"add_expense\"},\n    {\"words\": [\"Add\", \"a\", \"$350\", \"software\", \"charge\", \"to\", \"Startup\", \"Budget\", \"group\"], \n     \"slots\": [\"O\", \"O\", \"B-amount\", \"O\", \"O\", \"O\", \"B-group\", \"I-group\", \"O\"], \"intent\": \"add_expense\"},\n    {\"words\": [\"Log\", \"$60\", \"Spotify\", \"family\", \"plan\", \"to\", \"Monthly\", \"Subscriptions\"], \n     \"slots\": [\"O\", \"B-amount\", \"B-service\", \"I-service\", \"I-service\", \"O\", \"B-group\", \"I-group\"], \"intent\": \"add_expense\"},\n    {\"words\": [\"Add\", \"equipment\", \"bill\", \"of\", \"$480\", \"to\", \"Band\", \"Practice\", \"group\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"B-amount\", \"O\", \"B-group\", \"I-group\", \"O\"], \"intent\": \"add_expense\"},\n    {\"words\": [\"Add\", \"a\", \"dinner\", \"bill\", \"of\", \"$240\", \"to\", \"Tahoe\", \"trip\", \"group\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"B-amount\", \"O\", \"B-group\", \"I-group\", \"O\"], \"intent\": \"add_expense\"},\n    {\"words\": [\"Record\", \"a\", \"payment\", \"of\", \"$75\", \"for\", \"internet\", \"to\", \"Utilities\", \"group\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"B-amount\", \"O\", \"B-service\", \"O\", \"B-group\", \"O\"], \"intent\": \"add_expense\"},\n    {\"words\": [\"Add\", \"$122.50\", \"restaurant\", \"bill\", \"to\", \"Weekend\", \"Fun\", \"group\"], \n     \"slots\": [\"O\", \"B-amount\", \"O\", \"O\", \"O\", \"B-group\", \"I-group\", \"O\"], \"intent\": \"add_expense\"},\n    {\"words\": [\"Log\", \"movie\", \"tickets\", \"expense\", \"of\", \"$42\", \"to\", \"Entertainment\", \"group\"], \n     \"slots\": [\"O\", \"B-service\", \"I-service\", \"O\", \"O\", \"B-amount\", \"O\", \"B-group\", \"O\"], \"intent\": \"add_expense\"},\n    {\"words\": [\"Add\", \"my\", \"share\", \"of\", \"$220\", \"for\", \"the\", \"concert\", \"to\", \"Music\", \"Expenses\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"B-amount\", \"O\", \"O\", \"B-service\", \"O\", \"B-group\", \"I-group\"], \"intent\": \"add_expense\"},\n    {\"words\": [\"Record\", \"$18.75\", \"for\", \"coffee\", \"in\", \"Office\", \"Supplies\", \"group\"], \n     \"slots\": [\"O\", \"B-amount\", \"O\", \"B-service\", \"O\", \"B-group\", \"I-group\", \"O\"], \"intent\": \"add_expense\"},\n    {\"words\": [\"Add\", \"expense\", \"of\", \"$550\", \"for\", \"hotel\", \"booking\", \"to\", \"Vacation\", \"2023\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"B-amount\", \"O\", \"B-service\", \"I-service\", \"O\", \"B-group\", \"I-group\"], \"intent\": \"add_expense\"},\n    \n    # add_member\n    {\"words\": [\"Add\", \"Sarah\", \"to\", \"Startup\", \"Budget\", \"group\"], \n     \"slots\": [\"O\", \"B-person\", \"O\", \"B-group\", \"I-group\", \"O\"], \"intent\": \"add_member\"},\n    {\"words\": [\"Add\", \"Charlie\", \"to\", \"group\", \"Travel\", \"Friends\"], \n     \"slots\": [\"O\", \"B-person\", \"O\", \"O\", \"B-group\", \"I-group\"], \"intent\": \"add_member\"},\n    {\"words\": [\"Add\", \"Mike\", \"to\", \"the\", \"House\", \"Bills\", \"group\"], \n     \"slots\": [\"O\", \"B-person\", \"O\", \"O\", \"B-group\", \"I-group\", \"O\"], \"intent\": \"add_member\"},\n    {\"words\": [\"Add\", \"multiple\", \"people\", \":\", \"Josh\", \",\", \"Amy\", \",\", \"and\", \"Chris\", \"to\", \"Tahoe\", \"Trip\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"B-person\", \"O\", \"B-person\", \"O\", \"O\", \"B-person\", \"O\", \"B-group\", \"I-group\"], \"intent\": \"add_member\"},\n    {\"words\": [\"Include\", \"Samantha\", \"in\", \"the\", \"Office\", \"Lunch\", \"group\"], \n     \"slots\": [\"O\", \"B-person\", \"O\", \"O\", \"B-group\", \"I-group\", \"O\"], \"intent\": \"add_member\"},\n    {\"words\": [\"Add\", \"both\", \"David\", \"and\", \"Emily\", \"to\", \"Weekend\", \"Fun\"], \n     \"slots\": [\"O\", \"O\", \"B-person\", \"O\", \"B-person\", \"O\", \"B-group\", \"I-group\"], \"intent\": \"add_member\"},\n    {\"words\": [\"Include\", \"my\", \"roommate\", \"Jennifer\", \"in\", \"Utilities\", \"group\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"B-person\", \"O\", \"B-group\", \"O\"], \"intent\": \"add_member\"},\n    {\"words\": [\"Add\", \"new\", \"team\", \"member\", \"Richard\", \"to\", \"Project\", \"Alpha\", \"expenses\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"B-person\", \"O\", \"B-group\", \"I-group\", \"O\"], \"intent\": \"add_member\"},\n    {\"words\": [\"Include\", \"Robert\", \",\", \"Sandra\", \"and\", \"Tim\", \"in\", \"the\", \"Hiking\", \"Club\"], \n     \"slots\": [\"O\", \"B-person\", \"O\", \"B-person\", \"O\", \"B-person\", \"O\", \"O\", \"B-group\", \"I-group\"], \"intent\": \"add_member\"},\n    \n    # check_balance\n    {\"words\": [\"What's\", \"my\", \"share\", \"of\", \"rent\", \"in\", \"House\", \"Bills\", \"?\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-group\", \"I-group\", \"O\"], \"intent\": \"check_balance\"},\n    {\"words\": [\"Do\", \"I\", \"owe\", \"the\", \"group\", \"money\", \"?\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], \"intent\": \"check_balance\"},\n    {\"words\": [\"What's\", \"my\", \"total\", \"due\", \"across\", \"all\", \"groups\", \"?\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], \"intent\": \"check_balance\"},\n    {\"words\": [\"Do\", \"I\", \"owe\", \"anyone\", \"in\", \"the\", \"Startup\", \"Budget\", \"group\", \"?\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-group\", \"I-group\", \"O\", \"O\"], \"intent\": \"check_balance\"},\n    {\"words\": [\"How\", \"much\", \"do\", \"I\", \"owe\", \"in\", \"the\", \"group\", \"for\", \"my\", \"band\", \"practice\", \"?\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-group\", \"I-group\", \"O\"], \"intent\": \"check_balance\"},\n    {\"words\": [\"Am\", \"I\", \"owed\", \"money\", \"from\", \"groups\", \"?\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], \"intent\": \"check_balance\"},\n    {\"words\": [\"Show\", \"me\", \"my\", \"balance\", \"in\", \"Vacation\", \"2023\", \"group\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"B-group\", \"I-group\", \"O\"], \"intent\": \"check_balance\"},\n    {\"words\": [\"How\", \"much\", \"does\", \"Sarah\", \"owe\", \"me\", \"in\", \"House\", \"Bills\", \"?\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"B-person\", \"O\", \"O\", \"O\", \"B-group\", \"I-group\", \"O\"], \"intent\": \"check_balance\"},\n    {\"words\": [\"What's\", \"the\", \"current\", \"balance\", \"of\", \"Weekend\", \"Fun\", \"group\", \"?\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"B-group\", \"I-group\", \"O\", \"O\"], \"intent\": \"check_balance\"},\n    {\"words\": [\"Check\", \"if\", \"I\", \"owe\", \"anything\", \"for\", \"the\", \"Office\", \"Lunch\", \"expenses\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-group\", \"I-group\", \"O\"], \"intent\": \"check_balance\"},\n    {\"words\": [\"Does\", \"anyone\", \"owe\", \"me\", \"money\", \"in\", \"the\", \"Music\", \"Expenses\", \"group\", \"?\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-group\", \"I-group\", \"O\", \"O\"], \"intent\": \"check_balance\"},\n    {\"words\": [\"What's\", \"my\", \"balance\", \"with\", \"Chris\", \"across\", \"all\", \"shared\", \"groups\", \"?\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"B-person\", \"O\", \"O\", \"O\", \"O\", \"O\"], \"intent\": \"check_balance\"},\n    \n    # create_group\n    {\"words\": [\"Create\", \"a\", \"group\", \"called\", \"Travel\", \"Friends\", \"with\", \"Bob\", \"and\", \"Alice\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"B-group\", \"I-group\", \"O\", \"B-person\", \"O\", \"B-person\"], \"intent\": \"create_group\"},\n    {\"words\": [\"Create\", \"a\", \"new\", \"group\", \"Monthly\", \"Subscriptions\", \"with\", \"Alex\", \"and\", \"Ben\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"B-group\", \"I-group\", \"O\", \"B-person\", \"O\", \"B-person\"], \"intent\": \"create_group\"},\n    {\"words\": [\"Start\", \"a\", \"group\", \"called\", \"Startup\", \"Budget\", \"with\", \"John\", \"and\", \"Emma\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"B-group\", \"I-group\", \"O\", \"B-person\", \"O\", \"B-person\"], \"intent\": \"create_group\"},\n    {\"words\": [\"Make\", \"a\", \"group\", \"for\", \"House\", \"Bills\", \"with\", \"Lisa\", \"and\", \"Tom\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"B-group\", \"I-group\", \"O\", \"B-person\", \"O\", \"B-person\"], \"intent\": \"create_group\"},\n    {\"words\": [\"Create\", \"a\", \"new\", \"expense\", \"group\", \"called\", \"Office\", \"Lunch\", \"with\", \"coworkers\", \"Jim\", \"and\", \"Pam\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-group\", \"I-group\", \"O\", \"O\", \"B-person\", \"O\", \"B-person\"], \"intent\": \"create_group\"},\n    {\"words\": [\"Set\", \"up\", \"a\", \"group\", \"named\", \"Weekend\", \"Fun\", \"with\", \"my\", \"friends\", \"Kate\", \"and\", \"Mark\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"B-group\", \"I-group\", \"O\", \"O\", \"O\", \"B-person\", \"O\", \"B-person\"], \"intent\": \"create_group\"},\n    {\"words\": [\"Make\", \"a\", \"new\", \"group\", \"for\", \"our\", \"Vacation\", \"2023\", \"with\", \"Rachel\", \",\", \"Ross\", \"and\", \"Joey\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-group\", \"I-group\", \"O\", \"B-person\", \"O\", \"B-person\", \"O\", \"B-person\"], \"intent\": \"create_group\"},\n    {\"words\": [\"Create\", \"Utilities\", \"group\", \"with\", \"my\", \"roommates\", \"Sam\", \"and\", \"Jessica\"], \n     \"slots\": [\"O\", \"B-group\", \"O\", \"O\", \"O\", \"O\", \"B-person\", \"O\", \"B-person\"], \"intent\": \"create_group\"},\n    {\"words\": [\"Start\", \"a\", \"Music\", \"Expenses\", \"group\", \"with\", \"bandmates\", \"Dave\", \",\", \"Steve\", \"and\", \"Michael\"], \n     \"slots\": [\"O\", \"O\", \"B-group\", \"I-group\", \"O\", \"O\", \"O\", \"B-person\", \"O\", \"B-person\", \"O\", \"B-person\"], \"intent\": \"create_group\"},\n    {\"words\": [\"Create\", \"a\", \"Hiking\", \"Club\", \"expense\", \"tracker\", \"with\", \"Laura\", \"and\", \"Daniel\"], \n     \"slots\": [\"O\", \"O\", \"B-group\", \"I-group\", \"O\", \"O\", \"O\", \"B-person\", \"O\", \"B-person\"], \"intent\": \"create_group\"},\n    \n    # group_summary\n    {\"words\": [\"Show\", \"breakdown\", \"for\", \"Weekend\", \"Warriors\", \"group\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"B-group\", \"I-group\", \"O\"], \"intent\": \"group_summary\"},\n    {\"words\": [\"Show\", \"me\", \"a\", \"summary\", \"of\", \"the\", \"group\", \"for\", \"my\", \"band\", \"practice\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-group\", \"I-group\"], \"intent\": \"group_summary\"},\n    {\"words\": [\"Show\", \"full\", \"activity\", \"of\", \"Startup\", \"Budget\", \"group\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"B-group\", \"I-group\", \"O\"], \"intent\": \"group_summary\"},\n    {\"words\": [\"Summary\", \"of\", \"all\", \"groups\", \"with\", \"pending\", \"balances\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], \"intent\": \"group_summary\"},\n    {\"words\": [\"Show\", \"transaction\", \"history\", \"for\", \"House\", \"Bills\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"B-group\", \"I-group\"], \"intent\": \"group_summary\"},\n    {\"words\": [\"Give\", \"me\", \"a\", \"detailed\", \"breakdown\", \"of\", \"Vacation\", \"2023\", \"expenses\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-group\", \"I-group\", \"O\"], \"intent\": \"group_summary\"},\n    {\"words\": [\"Show\", \"all\", \"transactions\", \"in\", \"the\", \"Office\", \"Lunch\", \"group\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"B-group\", \"I-group\", \"O\"], \"intent\": \"group_summary\"},\n    {\"words\": [\"Summarize\", \"spending\", \"in\", \"Weekend\", \"Fun\", \"group\", \"by\", \"category\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"B-group\", \"I-group\", \"O\", \"O\", \"O\"], \"intent\": \"group_summary\"},\n    {\"words\": [\"Show\", \"expense\", \"breakdown\", \"for\", \"Music\", \"Expenses\", \"by\", \"month\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"B-group\", \"I-group\", \"O\", \"O\"], \"intent\": \"group_summary\"},\n    {\"words\": [\"I\", \"need\", \"a\", \"summary\", \"of\", \"Hiking\", \"Club\", \"expenses\", \"from\", \"last\", \"month\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"B-group\", \"I-group\", \"O\", \"O\", \"O\", \"O\"], \"intent\": \"group_summary\"},\n    {\"words\": [\"Let\", \"me\", \"see\", \"all\", \"payments\", \"in\", \"Utilities\", \"group\", \"since\", \"January\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-group\", \"O\", \"O\", \"O\"], \"intent\": \"group_summary\"},\n    \n    # hide_groups\n    {\"words\": [\"Hide\", \"all\", \"my\", \"groups\", \"with\", \"zero\", \"balance\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], \"intent\": \"hide_groups\"},\n    {\"words\": [\"Hide\", \"inactive\", \"groups\", \"from\", \"my\", \"dashboard\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], \"intent\": \"hide_groups\"},\n    {\"words\": [\"Don't\", \"show\", \"settled\", \"groups\", \"in\", \"my\", \"list\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], \"intent\": \"hide_groups\"},\n    {\"words\": [\"Hide\", \"all\", \"groups\", \"that\", \"are\", \"fully\", \"paid\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], \"intent\": \"hide_groups\"},\n    {\"words\": [\"Remove\", \"groups\", \"with\", \"no\", \"activity\", \"for\", \"over\", \"3\", \"months\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], \"intent\": \"hide_groups\"},\n    {\"words\": [\"Hide\", \"completed\", \"group\", \"expenses\", \"from\", \"view\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], \"intent\": \"hide_groups\"},\n    {\"words\": [\"Don't\", \"display\", \"archived\", \"groups\", \"in\", \"my\", \"feed\"], \n     \"slots\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], \"intent\": \"hide_groups\"},\n]",
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-06-17T07:30:44.907373Z",
     "iopub.execute_input": "2025-06-17T07:30:44.907726Z",
     "iopub.status.idle": "2025-06-17T07:31:16.920413Z",
     "shell.execute_reply.started": "2025-06-17T07:30:44.907699Z",
     "shell.execute_reply": "2025-06-17T07:31:16.919529Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# --------- 2. Label Mappings ---------\nintents = list(set(item[\"intent\"] for item in data))\nintent2id = {intent: idx for idx, intent in enumerate(intents)}\nid2intent = {v: k for k, v in intent2id.items()}\n\nslot_labels = set()\nfor item in data:\n    slot_labels.update(item[\"slots\"])\nslot_labels = sorted(slot_labels)\nslot_label2id = {label: idx for idx, label in enumerate(slot_labels)}\nid2slot_label = {v: k for k, v in slot_label2id.items()}\n\nprint(\"Intents:\", intent2id)\nprint(\"Slots:\", slot_label2id)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-06-17T07:59:19.071762Z",
     "iopub.execute_input": "2025-06-17T07:59:19.072580Z",
     "iopub.status.idle": "2025-06-17T07:59:19.079426Z",
     "shell.execute_reply.started": "2025-06-17T07:59:19.072554Z",
     "shell.execute_reply": "2025-06-17T07:59:19.078578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Intents: {'hide_groups': 0, 'add_member': 1, 'check_balance': 2, 'create_group': 3, 'group_summary': 4, 'add_expense': 5}\nSlots: {'B-amount': 0, 'B-group': 1, 'B-person': 2, 'B-service': 3, 'I-group': 4, 'I-service': 5, 'O': 6}\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": "# --------- 3. Tokenizer ---------\ntokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-06-17T07:59:22.435958Z",
     "iopub.execute_input": "2025-06-17T07:59:22.436658Z",
     "iopub.status.idle": "2025-06-17T07:59:22.555017Z",
     "shell.execute_reply.started": "2025-06-17T07:59:22.436606Z",
     "shell.execute_reply": "2025-06-17T07:59:22.554256Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": "# --------- 4. Dataset ---------\ndef tokenize_and_align_labels(texts, slot_labels_list):\n    encodings = tokenizer(texts, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)\n    all_labels = []\n    for i, labels in enumerate(slot_labels_list):\n        word_ids = encodings.word_ids(batch_index=i)\n        previous_word_idx = None\n        label_ids = []\n        for word_idx in word_ids:\n            if word_idx is None:\n                label_ids.append(-100)\n            elif word_idx != previous_word_idx:\n                label_ids.append(slot_label2id.get(labels[word_idx], slot_label2id[\"O\"]))\n            else:\n                label_ids.append(-100)\n            previous_word_idx = word_idx\n        all_labels.append(label_ids)\n    return encodings, all_labels\n\nclass JointDataset(Dataset):\n    def __init__(self, data):\n        self.texts = [item[\"words\"] for item in data]\n        self.slots = [item[\"slots\"] for item in data]\n        self.intents = [intent2id[item[\"intent\"]] for item in data]\n        self.encodings, self.slot_labels = tokenize_and_align_labels(self.texts, self.slots)\n    def __len__(self):\n        return len(self.intents)\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items() if key != \"offset_mapping\"}\n        item['labels'] = torch.tensor(self.slot_labels[idx])\n        item['intent_label'] = torch.tensor(self.intents[idx])\n        return item\n\ndataset = JointDataset(data)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-06-17T07:59:25.218207Z",
     "iopub.execute_input": "2025-06-17T07:59:25.218490Z",
     "iopub.status.idle": "2025-06-17T07:59:25.229868Z",
     "shell.execute_reply.started": "2025-06-17T07:59:25.218472Z",
     "shell.execute_reply": "2025-06-17T07:59:25.228945Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": "# --------- 5. Model ---------\nclass JointBERT(nn.Module):\n    def __init__(self, num_intents, num_slots):\n        super().__init__()\n        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n        hidden_size = self.bert.config.hidden_size\n        self.intent_classifier = nn.Linear(hidden_size, num_intents)\n        self.slot_classifier = nn.Linear(hidden_size, num_slots)\n    def forward(self, input_ids, attention_mask, labels=None, intent_label=None):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        sequence_output = outputs.last_hidden_state\n        pooled_output = outputs.pooler_output\n        intent_logits = self.intent_classifier(pooled_output)\n        slot_logits = self.slot_classifier(sequence_output)\n        loss = None\n        if labels is not None and intent_label is not None:\n            loss_fct = nn.CrossEntropyLoss()\n            slot_loss_fct = nn.CrossEntropyLoss(ignore_index=-100)\n            intent_loss = loss_fct(intent_logits, intent_label)\n            slot_loss = slot_loss_fct(slot_logits.view(-1, slot_logits.shape[-1]), labels.view(-1))\n            loss = intent_loss + slot_loss\n        return loss, intent_logits, slot_logits\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = JointBERT(num_intents=len(intent2id), num_slots=len(slot_label2id)).to(device)\noptimizer = AdamW(model.parameters(), lr=5e-5)\n\n# Define difficulty measurement for curriculum learning\ndef calculate_example_difficulty(example):\n    \"\"\"\n    Calculate difficulty score for an example based on multiple factors:\n    1. Input length - longer inputs are generally harder to process\n    2. Number of slots - more slots means more complexity\n    3. Entity density - more entities per word increases difficulty\n    4. Multiple entities of same type - harder to disambiguate\n    5. Intent complexity - some intents are inherently more complex\n    \"\"\"\n    # Factor 1: Input length\n    input_length = len(example[\"words\"])\n    length_score = min(1.0, input_length / 15)  # Normalize by max expected length\n    \n    # Factor 2: Number of non-\"O\" slots\n    slot_count = sum(1 for slot in example[\"slots\"] if slot != \"O\")\n    slot_score = min(1.0, slot_count / 8)  # Normalize by max expected slots\n    \n    # Factor 3: Entity density\n    if input_length > 0:\n        entity_density = slot_count / input_length\n    else:\n        entity_density = 0\n    density_score = min(1.0, entity_density * 3)  # Scale appropriately\n    \n    # Factor 4: Multiple entities of same type\n    entity_types = {}\n    current_entity = None\n    for slot in example[\"slots\"]:\n        if slot.startswith(\"B-\"):\n            entity_type = slot[2:]\n            entity_types[entity_type] = entity_types.get(entity_type, 0) + 1\n    \n    duplicate_entity_score = sum(min(1.0, (count - 1) * 0.5) for count in entity_types.values())\n    \n    # Factor 5: Intent complexity (based on domain knowledge)\n    intent_complexity = {\n        \"hide_groups\": 0.3,      # Simple command\n        \"check_balance\": 0.4,    # Simple query\n        \"group_summary\": 0.5,    # Information retrieval\n        \"create_group\": 0.7,     # Creation with multiple parameters\n        \"add_member\": 0.8,       # Modification with entity reference\n        \"add_expense\": 1.0       # Complex with amount and multiple references\n    }\n    intent_score = intent_complexity.get(example[\"intent\"], 0.5)\n    \n    # Combine all factors with appropriate weights\n    weights = {\n        \"length\": 0.15,\n        \"slots\": 0.25,\n        \"density\": 0.2,\n        \"duplicates\": 0.15,\n        \"intent\": 0.25\n    }\n    \n    difficulty = (\n        weights[\"length\"] * length_score +\n        weights[\"slots\"] * slot_score +\n        weights[\"density\"] * density_score +\n        weights[\"duplicates\"] * duplicate_entity_score +\n        weights[\"intent\"] * intent_score\n    )\n    \n    return difficulty\n\ntrain_loader = DataLoader(dataset, batch_size=4, shuffle=True)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-06-17T07:59:29.163268Z",
     "iopub.execute_input": "2025-06-17T07:59:29.163597Z",
     "iopub.status.idle": "2025-06-17T07:59:29.387491Z",
     "shell.execute_reply.started": "2025-06-17T07:59:29.163572Z",
     "shell.execute_reply": "2025-06-17T07:59:29.386575Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# --------- 6. Training with Curriculum Learning ---------\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Sort training examples by difficulty\nexample_difficulties = [(i, calculate_example_difficulty(data[i])) for i in range(len(data))]\nexample_difficulties.sort(key=lambda x: x[1])  # Sort by difficulty\n\n# Visualize the difficulty distribution\ndifficulties = [diff for _, diff in example_difficulties]\nplt.figure(figsize=(10, 5))\nplt.hist(difficulties, bins=10, alpha=0.7)\nplt.title('Distribution of Example Difficulties')\nplt.xlabel('Difficulty Score')\nplt.ylabel('Number of Examples')\nplt.axvline(x=np.percentile(difficulties, 33), color='r', linestyle='--', alpha=0.7, label='33rd percentile')\nplt.axvline(x=np.percentile(difficulties, 66), color='g', linestyle='--', alpha=0.7, label='66th percentile')\nplt.legend()\nplt.grid(alpha=0.3)\nplt.show()\n\nprint(f\"Difficulty statistics:\")\nprint(f\"  Min: {min(difficulties):.2f}\")\nprint(f\"  Max: {max(difficulties):.2f}\")\nprint(f\"  Mean: {np.mean(difficulties):.2f}\")\nprint(f\"  Median: {np.median(difficulties):.2f}\")\n\n# Create curriculum stages\nnum_stages = 3\ncurriculum_stages = []\n\n# First stage: easy examples (bottom 33%)\neasy_threshold = np.percentile(difficulties, 33)\neasy_indices = [idx for idx, diff in example_difficulties if diff <= easy_threshold]\ncurriculum_stages.append([data[i] for i in easy_indices])\n\n# Second stage: easy + medium examples (bottom 66%)\nmedium_threshold = np.percentile(difficulties, 66)\nmedium_indices = [idx for idx, diff in example_difficulties if diff <= medium_threshold]\ncurriculum_stages.append([data[i] for i in medium_indices])\n\n# Third stage: all examples\ncurriculum_stages.append(data)\n\nprint(f\"Curriculum stages created with {[len(stage) for stage in curriculum_stages]} examples per stage\")\n\n# Create validation set (20% of data)\nfrom sklearn.model_selection import train_test_split\ntrain_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\nval_dataset = JointDataset(val_data)\nval_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n\n# Function to evaluate model\ndef evaluate_model(model, data_loader):\n    model.eval()\n    intent_correct = 0\n    slot_correct = 0\n    slot_total = 0\n    total_examples = 0\n    total_loss = 0\n    \n    with torch.no_grad():\n        for batch in data_loader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            loss, intent_logits, slot_logits = model(\n                input_ids=batch[\"input_ids\"],\n                attention_mask=batch[\"attention_mask\"],\n                labels=batch[\"labels\"],\n                intent_label=batch[\"intent_label\"]\n            )\n            \n            # Intent accuracy\n            intent_preds = torch.argmax(intent_logits, dim=1)\n            intent_correct += (intent_preds == batch[\"intent_label\"]).sum().item()\n            \n            # Slot accuracy (ignoring padding tokens)\n            slot_preds = torch.argmax(slot_logits, dim=2)\n            active_slots = batch[\"labels\"] != -100\n            slot_correct += ((slot_preds == batch[\"labels\"]) & active_slots).sum().item()\n            slot_total += active_slots.sum().item()\n            \n            total_examples += batch[\"intent_label\"].size(0)\n            total_loss += loss.item() * batch[\"intent_label\"].size(0)\n    \n    intent_accuracy = intent_correct / total_examples if total_examples > 0 else 0\n    slot_accuracy = slot_correct / slot_total if slot_total > 0 else 0\n    avg_loss = total_loss / total_examples if total_examples > 0 else float('inf')\n    \n    return {\n        \"loss\": avg_loss,\n        \"intent_accuracy\": intent_accuracy,\n        \"slot_accuracy\": slot_accuracy,\n        \"joint_accuracy\": (intent_accuracy + slot_accuracy) / 2\n    }\n\n# Training with curriculum learning\nmodel.train()\ntotal_epochs = 9  # 3 stages × 3 epochs per stage\nepochs_per_stage = 3\nmetrics_history = {\n    \"loss\": [],\n    \"intent_accuracy\": [],\n    \"slot_accuracy\": [],\n    \"joint_accuracy\": []\n}\n\nprint(\"\\n--- Starting Curriculum Learning Training ---\")\n\nfor stage in range(num_stages):\n    print(f\"\\n--- Stage {stage+1}/{num_stages} - {len(curriculum_stages[stage])} examples ---\")\n    stage_data = curriculum_stages[stage]\n    stage_dataset = JointDataset(stage_data)\n    stage_loader = DataLoader(stage_dataset, batch_size=4, shuffle=True)\n    \n    for epoch in range(epochs_per_stage):\n        # Training epoch\n        model.train()\n        total_loss = 0\n        for batch in stage_loader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            optimizer.zero_grad()\n            loss, _, _ = model(\n                input_ids=batch[\"input_ids\"],\n                attention_mask=batch[\"attention_mask\"],\n                labels=batch[\"labels\"],\n                intent_label=batch[\"intent_label\"]\n            )\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n        \n        # Evaluation\n        model.eval()\n        val_metrics = evaluate_model(model, val_loader)\n        metrics_history[\"loss\"].append(val_metrics[\"loss\"])\n        metrics_history[\"intent_accuracy\"].append(val_metrics[\"intent_accuracy\"])\n        metrics_history[\"slot_accuracy\"].append(val_metrics[\"slot_accuracy\"])\n        metrics_history[\"joint_accuracy\"].append(val_metrics[\"joint_accuracy\"])\n        \n        global_epoch = (stage * epochs_per_stage) + epoch\n        print(f\"Epoch {global_epoch+1}/{total_epochs} - \"\n              f\"Train Loss: {total_loss/len(stage_loader):.4f}, \"\n              f\"Val Loss: {val_metrics['loss']:.4f}, \"\n              f\"Intent Acc: {val_metrics['intent_accuracy']:.4f}, \"\n              f\"Slot Acc: {val_metrics['slot_accuracy']:.4f}\")\n\n# Plot learning curves\nplt.figure(figsize=(12, 8))\n\nplt.subplot(2, 2, 1)\nplt.plot(range(1, total_epochs+1), metrics_history[\"loss\"])\nplt.title('Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.grid(alpha=0.3)\n\nplt.subplot(2, 2, 2)\nplt.plot(range(1, total_epochs+1), metrics_history[\"intent_accuracy\"])\nplt.title('Intent Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.grid(alpha=0.3)\n\nplt.subplot(2, 2, 3)\nplt.plot(range(1, total_epochs+1), metrics_history[\"slot_accuracy\"])\nplt.title('Slot Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.grid(alpha=0.3)\n\nplt.subplot(2, 2, 4)\nplt.plot(range(1, total_epochs+1), metrics_history[\"joint_accuracy\"])\nplt.title('Joint Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.grid(alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Highlight curriculum transitions\nplt.figure(figsize=(10, 6))\nplt.plot(range(1, total_epochs+1), metrics_history[\"joint_accuracy\"], marker='o')\nplt.axvline(x=epochs_per_stage + 0.5, color='r', linestyle='--', alpha=0.7, label='Stage 1 → 2')\nplt.axvline(x=2*epochs_per_stage + 0.5, color='g', linestyle='--', alpha=0.7, label='Stage 2 → 3')\nplt.title('Learning Progress with Curriculum Stages')\nplt.xlabel('Epoch')\nplt.ylabel('Joint Accuracy')\nplt.legend()\nplt.grid(alpha=0.3)\nplt.show()",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-06-17T07:59:32.494232Z",
     "iopub.execute_input": "2025-06-17T07:59:32.494572Z",
     "iopub.status.idle": "2025-06-17T08:00:27.134834Z",
     "shell.execute_reply.started": "2025-06-17T07:59:32.494551Z",
     "shell.execute_reply": "2025-06-17T08:00:27.133935Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# --------- 7. Comparison with Standard Training ---------\nimport copy\n\n# Create a copy of the model for standard training\nstandard_model = copy.deepcopy(model)\nstandard_model = JointBERT(num_intents=len(intent2id), num_slots=len(slot_label2id)).to(device)\nstandard_optimizer = AdamW(standard_model.parameters(), lr=5e-5)\n\n# Create dataset for standard training (without curriculum)\nstandard_train_dataset = JointDataset(train_data)\nstandard_train_loader = DataLoader(standard_train_dataset, batch_size=4, shuffle=True)\n\n# Training metrics for standard approach\nstandard_metrics_history = {\n    \"loss\": [],\n    \"intent_accuracy\": [],\n    \"slot_accuracy\": [],\n    \"joint_accuracy\": []\n}\n\nprint(\"\\n--- Starting Standard Training (No Curriculum) ---\")\n\n# Train for the same total number of epochs\nfor epoch in range(total_epochs):\n    # Training epoch\n    standard_model.train()\n    total_loss = 0\n    for batch in standard_train_loader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        standard_optimizer.zero_grad()\n        loss, _, _ = standard_model(\n            input_ids=batch[\"input_ids\"],\n            attention_mask=batch[\"attention_mask\"],\n            labels=batch[\"labels\"],\n            intent_label=batch[\"intent_label\"]\n        )\n        loss.backward()\n        standard_optimizer.step()\n        total_loss += loss.item()\n    \n    # Evaluation\n    standard_model.eval()\n    val_metrics = evaluate_model(standard_model, val_loader)\n    standard_metrics_history[\"loss\"].append(val_metrics[\"loss\"])\n    standard_metrics_history[\"intent_accuracy\"].append(val_metrics[\"intent_accuracy\"])\n    standard_metrics_history[\"slot_accuracy\"].append(val_metrics[\"slot_accuracy\"])\n    standard_metrics_history[\"joint_accuracy\"].append(val_metrics[\"joint_accuracy\"])\n    \n    print(f\"Epoch {epoch+1}/{total_epochs} - \"\n          f\"Train Loss: {total_loss/len(standard_train_loader):.4f}, \"\n          f\"Val Loss: {val_metrics['loss']:.4f}, \"\n          f\"Intent Acc: {val_metrics['intent_accuracy']:.4f}, \"\n          f\"Slot Acc: {val_metrics['slot_accuracy']:.4f}\")\n\n# Comparison plots\nplt.figure(figsize=(15, 10))\n\n# Loss comparison\nplt.subplot(2, 2, 1)\nplt.plot(range(1, total_epochs+1), metrics_history[\"loss\"], label='Curriculum Learning')\nplt.plot(range(1, total_epochs+1), standard_metrics_history[\"loss\"], label='Standard Training')\nplt.title('Validation Loss Comparison')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.grid(alpha=0.3)\n\n# Intent accuracy comparison\nplt.subplot(2, 2, 2)\nplt.plot(range(1, total_epochs+1), metrics_history[\"intent_accuracy\"], label='Curriculum Learning')\nplt.plot(range(1, total_epochs+1), standard_metrics_history[\"intent_accuracy\"], label='Standard Training')\nplt.title('Intent Accuracy Comparison')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.grid(alpha=0.3)\n\n# Slot accuracy comparison\nplt.subplot(2, 2, 3)\nplt.plot(range(1, total_epochs+1), metrics_history[\"slot_accuracy\"], label='Curriculum Learning')\nplt.plot(range(1, total_epochs+1), standard_metrics_history[\"slot_accuracy\"], label='Standard Training')\nplt.title('Slot Accuracy Comparison')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.grid(alpha=0.3)\n\n# Joint accuracy comparison\nplt.subplot(2, 2, 4)\nplt.plot(range(1, total_epochs+1), metrics_history[\"joint_accuracy\"], label='Curriculum Learning')\nplt.plot(range(1, total_epochs+1), standard_metrics_history[\"joint_accuracy\"], label='Standard Training')\nplt.title('Joint Accuracy Comparison')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.grid(alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Final performance comparison\nprint(\"\\n--- Final Performance Comparison ---\")\nprint(f\"{'Metric':<20} {'Curriculum':<15} {'Standard':<15} {'Difference':<15}\")\nprint(\"-\" * 65)\n\nfor metric in [\"loss\", \"intent_accuracy\", \"slot_accuracy\", \"joint_accuracy\"]:\n    curriculum_value = metrics_history[metric][-1]\n    standard_value = standard_metrics_history[metric][-1]\n    difference = curriculum_value - standard_value\n    difference_str = f\"{difference:.4f} ({difference/standard_value*100:.1f}%)\" if metric != \"loss\" else f\"{difference:.4f}\"\n    \n    # Improvement indicator\n    if metric == \"loss\":\n        is_better = difference < 0\n    else:\n        is_better = difference > 0\n    \n    indicator = \"✓\" if is_better else \"✗\"\n    print(f\"{metric.replace('_', ' ').title():<20} {curriculum_value:.4f}{'':<8} {standard_value:.4f}{'':<8} {difference_str:<15} {indicator}\")\n\n# Analysis of performance on different difficulty levels\nprint(\"\\n--- Performance Analysis by Difficulty Level ---\")\n\n# Group test examples by difficulty\ndifficulty_ranges = {\n    \"Easy\": (0, easy_threshold),\n    \"Medium\": (easy_threshold, medium_threshold),\n    \"Hard\": (medium_threshold, float('inf'))\n}\n\n# Calculate difficulty for validation examples\nval_difficulties = [calculate_example_difficulty(example) for example in val_data]\n\n# Split validation data into difficulty groups\neasy_val = [i for i, diff in enumerate(val_difficulties) if diff <= easy_threshold]\nmedium_val = [i for i, diff in enumerate(val_difficulties) if easy_threshold < diff <= medium_threshold]\nhard_val = [i for i, diff in enumerate(val_difficulties) if diff > medium_threshold]\n\ndifficulty_groups = {\n    \"Easy\": easy_val,\n    \"Medium\": medium_val,\n    \"Hard\": hard_val\n}\n\n# Create datasets for each difficulty group\ndifficulty_datasets = {}\nfor difficulty, indices in difficulty_groups.items():\n    if indices:  # Only create datasets for non-empty groups\n        difficulty_data = [val_data[i] for i in indices]\n        difficulty_datasets[difficulty] = JointDataset(difficulty_data)\n\n# Evaluate both models on each difficulty group\nprint(f\"{'Difficulty':<10} {'Examples':<10} {'Curriculum Acc':<15} {'Standard Acc':<15} {'Difference':<15}\")\nprint(\"-\" * 65)\n\nfor difficulty, dataset in difficulty_datasets.items():\n    loader = DataLoader(dataset, batch_size=4, shuffle=False)\n    \n    # Skip if no examples in this difficulty range\n    if len(loader) == 0:\n        continue\n    \n    # Curriculum model performance\n    curr_metrics = evaluate_model(model, loader)\n    \n    # Standard model performance\n    std_metrics = evaluate_model(standard_model, loader)\n    \n    # Joint accuracy comparison\n    curr_acc = curr_metrics[\"joint_accuracy\"]\n    std_acc = std_metrics[\"joint_accuracy\"]\n    difference = curr_acc - std_acc\n    difference_str = f\"{difference:.4f} ({difference/std_acc*100:.1f}%)\" if std_acc > 0 else \"N/A\"\n    \n    # Improvement indicator\n    indicator = \"✓\" if difference > 0 else \"✗\"\n    if difference == 0:\n        indicator = \"-\"\n    \n    print(f\"{difficulty:<10} {len(dataset):<10} {curr_acc:.4f}{'':<8} {std_acc:.4f}{'':<8} {difference_str:<15} {indicator}\")\n\n# Analysis conclusion\nprint(\"\\nKey Findings:\")\nprint(\"1. Curriculum learning shows \" + \n      (\"better\" if metrics_history[\"joint_accuracy\"][-1] > standard_metrics_history[\"joint_accuracy\"][-1] else \"worse\") + \n      \" overall performance compared to standard training.\")\nprint(\"2. The biggest difference in performance is seen in \" + \n      (\"easy\" if curr_metrics[\"joint_accuracy\"] - std_metrics[\"joint_accuracy\"] > 0 else \"hard\") + \n      \" examples, suggesting that curriculum learning \" + \n      (\"helps\" if curr_metrics[\"joint_accuracy\"] - std_metrics[\"joint_accuracy\"] > 0 else \"may not help\") + \n      \" the model build a stronger foundation.\")\nprint(\"3. Learning rate is \" + \n      (\"faster\" if np.mean(metrics_history[\"joint_accuracy\"][:3]) > np.mean(standard_metrics_history[\"joint_accuracy\"][:3]) else \"slower\") + \n      \" in early epochs with curriculum learning, indicating \" + \n      (\"more\" if np.mean(metrics_history[\"joint_accuracy\"][:3]) > np.mean(standard_metrics_history[\"joint_accuracy\"][:3]) else \"less\") + \n      \" efficient initial learning.\")",
   "metadata": {
    "trusted": true
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# --------- 10. Alternative Curriculum Learning Approaches ---------\n\n# This cell provides alternative approaches to curriculum learning that could be explored\n\ndef get_difficulty_by_uncertainty(model, example, tokenizer):\n    \"\"\"Measure example difficulty by model uncertainty/confidence\n    \n    Higher uncertainty = more difficult example\n    This approach requires a pre-trained model to assess difficulty\n    \"\"\"\n    model.eval()\n    words = example[\"words\"]\n    inputs = tokenizer([words], is_split_into_words=True, return_tensors=\"pt\").to(device)\n    \n    with torch.no_grad():\n        _, intent_logits, slot_logits = model(inputs[\"input_ids\"], inputs[\"attention_mask\"])\n        \n        # Calculate uncertainty using entropy\n        intent_probs = torch.nn.functional.softmax(intent_logits, dim=1)\n        intent_entropy = -torch.sum(intent_probs * torch.log(intent_probs + 1e-10), dim=1).item()\n        \n        # Average slot entropy across sequence\n        slot_probs = torch.nn.functional.softmax(slot_logits, dim=2)\n        slot_entropy = -torch.sum(slot_probs * torch.log(slot_probs + 1e-10), dim=2)\n        avg_slot_entropy = torch.mean(slot_entropy).item()\n        \n    return intent_entropy + avg_slot_entropy\n\ndef get_difficulty_by_intent_distribution(example):\n    \"\"\"Curriculum based on intent distribution\n    \n    Train on one intent type at a time, starting with simpler intents\n    \"\"\"\n    # Predefined intent difficulty (domain knowledge)\n    intent_difficulty = {\n        \"check_balance\": 1,      # Simplest - mostly information retrieval\n        \"hide_groups\": 1,        # Simple - just a setting\n        \"group_summary\": 2,      # Medium - display structured info\n        \"create_group\": 3,       # More complex - creating entities with attributes\n        \"add_member\": 3,         # More complex - modifying entities\n        \"add_expense\": 4         # Most complex - numerical values, categories, etc.\n    }\n    \n    return intent_difficulty.get(example[\"intent\"], 5)  # Default to highest difficulty\n\ndef get_difficulty_by_slot_density(example):\n    \"\"\"Measure difficulty by the density of slots\n    \n    Higher slot density = more difficult example\n    \"\"\"\n    total_words = len(example[\"words\"])\n    if total_words == 0:\n        return 0\n        \n    slot_words = sum(1 for slot in example[\"slots\"] if slot != \"O\")\n    return slot_words / total_words\n\n# Example of a competence-based curriculum:\n# This approach adapts the curriculum based on model performance\ndef competence_based_curriculum(model, data, tokenizer, num_epochs=8):\n    \"\"\"\n    Implement a competence-based curriculum that adapts based on model performance\n    \"\"\"\n    # Split data into validation and training\n    from sklearn.model_selection import train_test_split\n    train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n    \n    # Calculate initial difficulty scores\n    difficulties = [(i, get_example_difficulty(example)) for i, example in enumerate(train_data)]\n    difficulties.sort(key=lambda x: x[1])\n    \n    # Start with easier 20% of examples\n    active_indices = set([idx for idx, _ in difficulties[:int(0.2 * len(difficulties))]])\n    \n    model.train()\n    val_dataset = JointDataset(val_data)\n    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n    \n    # Track performance history\n    performance_history = []\n    \n    for epoch in range(num_epochs):\n        # Create dataset from active examples\n        active_data = [train_data[i] for i in active_indices]\n        active_dataset = JointDataset(active_data)\n        active_loader = DataLoader(active_dataset, batch_size=4, shuffle=True)\n        \n        # Train for one epoch\n        total_loss = 0\n        for batch in active_loader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            optimizer.zero_grad()\n            loss, _, _ = model(\n                input_ids=batch[\"input_ids\"],\n                attention_mask=batch[\"attention_mask\"],\n                labels=batch[\"labels\"],\n                intent_label=batch[\"intent_label\"]\n            )\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n        \n        # Evaluate current performance\n        metrics = evaluate_model(model, val_loader)\n        performance_history.append(metrics[\"joint_accuracy\"])\n        print(f\"Epoch {epoch+1}/{num_epochs}, {len(active_indices)}/{len(train_data)} examples, \"\n              f\"loss: {total_loss/len(active_loader):.4f}, \"\n              f\"acc: {metrics['joint_accuracy']:.4f}\")\n        \n        # Adjust curriculum based on performance\n        # If performance plateaus, add more difficult examples\n        if epoch >= 2 and abs(performance_history[-1] - performance_history[-2]) < 0.01:\n            # Add next 10% of examples by difficulty\n            current_size = len(active_indices)\n            target_size = min(len(train_data), int(current_size * 1.1))\n            remaining = [(idx, diff) for idx, diff in difficulties if idx not in active_indices]\n            remaining.sort(key=lambda x: x[1])\n            \n            # Add easier remaining examples first\n            to_add = target_size - current_size\n            active_indices.update([idx for idx, _ in remaining[:to_add]])\n            \n            print(f\"  Performance plateau detected. Added {to_add} examples.\")\n    \n    return model, performance_history\n\n# Example usage (not executed to save computation time):\n\"\"\"\nprint(\"\\n--- Competence-based Curriculum Learning ---\")\ncompetence_model = JointBERT(num_intents=len(intent2id), num_slots=len(slot_label2id)).to(device)\ncompetence_optimizer = AdamW(competence_model.parameters(), lr=5e-5)\ncompetence_model, history = competence_based_curriculum(competence_model, data, tokenizer)\n\"\"\"\n\n# Other curriculum strategies that could be explored:\n# \n# 1. Mixed difficulty batches: Rather than training on all easy examples first,\n#    create batches with a mix of difficulties but weight towards easier examples initially\n#\n# 2. Task-specific curriculum: Train intent classification first, then slot filling\n#\n# 3. Intent-based curriculum: Train on one intent at a time in order of increasing complexity\n#\n# 4. Online difficulty assessment: Periodically re-assess example difficulty based on\n#    the model's current loss or uncertainty on each example",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# --------- 9. Curriculum Learning Evaluation ---------\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Function to evaluate model on test data\ndef evaluate_model(model, test_loader):\n    model.eval()\n    intent_correct = 0\n    slot_correct = 0\n    slot_total = 0\n    total = 0\n    \n    with torch.no_grad():\n        for batch in test_loader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            _, intent_logits, slot_logits = model(\n                input_ids=batch[\"input_ids\"],\n                attention_mask=batch[\"attention_mask\"]\n            )\n            \n            # Intent accuracy\n            intent_preds = torch.argmax(intent_logits, dim=1)\n            intent_correct += (intent_preds == batch[\"intent_label\"]).sum().item()\n            \n            # Slot accuracy (ignoring padding tokens)\n            slot_preds = torch.argmax(slot_logits, dim=2)\n            active_slots = batch[\"labels\"] != -100\n            slot_correct += ((slot_preds == batch[\"labels\"]) & active_slots).sum().item()\n            slot_total += active_slots.sum().item()\n            \n            total += batch[\"intent_label\"].size(0)\n    \n    intent_accuracy = intent_correct / total\n    slot_accuracy = slot_correct / slot_total if slot_total > 0 else 0\n    \n    return {\n        \"intent_accuracy\": intent_accuracy,\n        \"slot_accuracy\": slot_accuracy,\n        \"joint_accuracy\": (intent_accuracy + slot_accuracy) / 2\n    }\n\n# Visualize difficulty distribution\ndifficulties = [get_example_difficulty(example) for example in data]\n\nplt.figure(figsize=(10, 5))\nplt.hist(difficulties, bins=10, alpha=0.7)\nplt.title('Distribution of Example Difficulties')\nplt.xlabel('Difficulty Score')\nplt.ylabel('Number of Examples')\nplt.grid(alpha=0.3)\nplt.show()\n\n# Print difficulty statistics\nprint(f\"Difficulty statistics:\")\nprint(f\"  Min: {min(difficulties):.2f}\")\nprint(f\"  Max: {max(difficulties):.2f}\")\nprint(f\"  Mean: {np.mean(difficulties):.2f}\")\nprint(f\"  Median: {np.median(difficulties):.2f}\")\n\n# Create validation set from 20% of the data\nfrom sklearn.model_selection import train_test_split\n\ntrain_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\nval_dataset = JointDataset(val_data)\nval_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n\n# Training without curriculum learning (for comparison)\nno_curriculum_model = JointBERT(num_intents=len(intent2id), num_slots=len(slot_label2id)).to(device)\nno_curriculum_optimizer = AdamW(no_curriculum_model.parameters(), lr=5e-5)\ntrain_dataset = JointDataset(train_data)\ntrain_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n\nprint(\"\\n--- Training without curriculum learning ---\")\nno_curriculum_model.train()\nfor epoch in range(8):\n    total_loss = 0\n    for batch in train_loader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        no_curriculum_optimizer.zero_grad()\n        loss, _, _ = no_curriculum_model(\n            input_ids=batch[\"input_ids\"],\n            attention_mask=batch[\"attention_mask\"],\n            labels=batch[\"labels\"],\n            intent_label=batch[\"intent_label\"]\n        )\n        loss.backward()\n        no_curriculum_optimizer.step()\n        total_loss += loss.item()\n        \n    print(f\"Epoch {epoch+1}/8 loss: {total_loss/len(train_loader):.4f}\")\n    \n    # Evaluate after each epoch\n    metrics = evaluate_model(no_curriculum_model, val_loader)\n    print(f\"  Validation - Intent Acc: {metrics['intent_accuracy']:.4f}, Slot Acc: {metrics['slot_accuracy']:.4f}\")\n\n# Compare the two models\ncurriculum_metrics = evaluate_model(model, val_loader)\nno_curriculum_metrics = evaluate_model(no_curriculum_model, val_loader)\n\nprint(\"\\n--- Comparison of Models ---\")\nprint(\"With Curriculum Learning:\")\nprint(f\"  Intent Accuracy: {curriculum_metrics['intent_accuracy']:.4f}\")\nprint(f\"  Slot Accuracy: {curriculum_metrics['slot_accuracy']:.4f}\")\nprint(f\"  Joint Accuracy: {curriculum_metrics['joint_accuracy']:.4f}\")\n\nprint(\"\\nWithout Curriculum Learning:\")\nprint(f\"  Intent Accuracy: {no_curriculum_metrics['intent_accuracy']:.4f}\")\nprint(f\"  Slot Accuracy: {no_curriculum_metrics['slot_accuracy']:.4f}\")\nprint(f\"  Joint Accuracy: {no_curriculum_metrics['joint_accuracy']:.4f}\")\n\n# Plot learning curves\nplt.figure(figsize=(12, 6))\nplt.title('Accuracy Comparison')\nplt.bar(['Intent Acc (w/ CL)', 'Intent Acc', 'Slot Acc (w/ CL)', 'Slot Acc', 'Joint Acc (w/ CL)', 'Joint Acc'], \n        [curriculum_metrics['intent_accuracy'], no_curriculum_metrics['intent_accuracy'],\n         curriculum_metrics['slot_accuracy'], no_curriculum_metrics['slot_accuracy'],\n         curriculum_metrics['joint_accuracy'], no_curriculum_metrics['joint_accuracy']])\nplt.ylabel('Accuracy')\nplt.ylim(0, 1)\nplt.grid(axis='y', alpha=0.3)\nplt.show()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# --------- 8. Test ---------\ntest_sentences = [\n    \"Add expense of $20 to group Travel Friends\",\n    \"Add Sarah to Startup Budget group\",\n    \"What's my share of rent in House Bills?\",\n    \"Create a group called Travel Friends with Bob and Alice\",\n    \"Show me a summary of the group for my band practice\",\n    \"Hide all my groups with zero balance\"\n]\n\nfor sent in test_sentences:\n    intent, slots = predict(sent)\n    print(f\"\\nInput: {sent}\")\n    print(f\"Predicted intent: {intent}\")\n    print(f\"Predicted slots:\\n{json.dumps(slots, indent=2)}\")",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}