{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNIPS + Embedding-Augmented FLAN-T5\n",
    "Fine-tuning FLAN-T5 for real-world intent and slot detection using the SNIPS dataset with SBERT embeddings."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets accelerate sentence-transformers seqeval"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd, torch, json"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1. Load SNIPS dataset\n",
    "ds = load_dataset('snips_built_in_intents')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2. Format to T5-style examples\n",
    "def prepare(example):\n",
    "    intent = example['intent']\n",
    "    slots = example['slots']\n",
    "    example['target'] = json.dumps({'intent': intent, **slots})\n",
    "    return example\n",
    "\n",
    "ds = ds.map(prepare)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 3. Add embeddings\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "def add_embed(ex):\n",
    "    ex['emb'] = embedder.encode(ex['text']).tolist()\n",
    "    return ex\n",
    "\n",
    "ds = ds.map(add_embed)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 4. Tokenizer and FLAN-T5\n",
    "tokenizer = AutoTokenizer.from_pretrained('google/flan-t5-base')\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('google/flan-t5-base')\n",
    "\n",
    "def preprocess(ex):\n",
    "    prefix = ' '.join(map(lambda x: str(round(x, 4)), ex['emb'][:16]))\n",
    "    inp = prefix + ' | ' + ex['text']\n",
    "    tokens = tokenizer(inp, max_length=128, truncation=True)\n",
    "    tgt = tokenizer(ex['target'], max_length=64, truncation=True)\n",
    "    tokens['labels'] = tgt['input_ids']\n",
    "    return tokens\n",
    "\n",
    "tokenized = ds.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 5. Fine-tuning\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir='snips_augmented',\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    predict_with_generate=True,\n",
    "    fp16=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized['train'],\n",
    "    eval_dataset=tokenized['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer, model)\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 6. Inference\n",
    "def predict(text):\n",
    "    emb = embedder.encode(text)\n",
    "    prefix = ' '.join(map(lambda x: str(round(x,4)), emb[:16]))\n",
    "    inp = prefix + ' | ' + text\n",
    "    tokens = tokenizer(inp, return_tensors='pt').to(model.device)\n",
    "    out = model.generate(**tokens, max_length=64)\n",
    "    return tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "print(predict('Play the last song from Coldplay'))\n",
    "print(predict('Find me a restaurant in New York tomorrow night'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}